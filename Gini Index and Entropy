Problem 1
We plan to build a decision tree using 7 records in the file Problem1.xlsx. The task in this
problem is to find the first split using both Gini index and entropy as the impurity
measure. Calculate the purity improvement after the first split respectively.

Observation	X1	X2	X3	Y
1	1	1	1	1
2	1	1	-1	1
3	-1	1	-1	0
4	-1	-1	1	0
5	-1	-1	-1	0
6	1	-1	1	1
7	1	-1	-1	0

"1. Find the first split using both Gini index and entropy as the impurity 
measure"

-> Measures of node impurity and required to get determine node splits which will then define child nodes
-> Gini Index and Entropy aare the most commonly used nodes
-> Here we have Response Variable as "Y" and Predictors as "X1", "X2", "X3"

Gini Index for Variable X1	1	0	Row Total		
-1	0	3	3	Gini(0,3)	0
1	3	1	4	Gini(3,1)	0.375
Total		7		Gini(X1)	0.214285714
					
					
Gini Index for Variable X2	1	0	Row Total		
-1	1	3	4	Gini(1,3)	0.375
1	2	1	3	Gini(2,1)	0.444444444
Total		7		Gini(X2)	0.404761905
					
					
Gini Index for Variable X3	1	0	Row Total		
-1	1	3	4	Gini(1,3)	0.375
1	2	1	3	Gini(2,1)	0.444444444
Total		7		Gini(X3)	0.404761905


Entropy for Variable X1	1	0	Row Total
-1	0	3	3
1	3	1	4
Total		7	0.4635
			
			
Entropy for Variable X2	1	0	Row Total
-1	1	3	4
1	2	1	3
Total		7	0.8556
			
			
Entropy for Variable X3	1	0	Row Total
-1	1	3	4
1	2	1	3
Total		7	0.8556


As we see, Weighted Gini and Weighted Entropy are small for splitting the records with X1. 
So, 1st splitting should be done at X1 < 0. 
Purity improvement after first split at X1<0

For Gini Index, (0.49 – 0.21) *100/ 0.49 = 56.3 % 
For Entropy, (0.985 – 0.463) *100/ 0.985 = 52.99 %

